{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quora preprocessing \n",
    "\n",
    "**(~1:30h gpu run time)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\"../data/raw/train.csv\", low_memory=False)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = df_raw[df_raw.target == 0].sample(n=480_000, random_state=42)\n",
    "\n",
    "df = pd.concat(\n",
    "    [sampled_df, df_raw[df_raw.target == 1]]\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target samples\n",
    "df.shape[0] - 200_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test\n",
    "X, y = df.drop('target', axis=1), df.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.10, random_state=42\n",
    ")\n",
    "\n",
    "train_df = X_train\n",
    "train_df['target'] = y_train\n",
    "\n",
    "test_df = X_test\n",
    "test_df['target'] = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "resampled_df = X_resampled\n",
    "resampled_df['target'] = y_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nlpaug\n",
    "\n",
    "Using:\n",
    "  * KeyboardAug\n",
    "  * ContextualWordEmbsAug\n",
    "  * SynonymAug\n",
    "  * BackTranslationAug\n",
    "  * SpellingAug\n",
    "\n",
    "80_000 new examples for each augment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "\n",
    "df_1 = train_df[train_df.target==1].copy()\n",
    "\n",
    "texts = list(df_1.question_text)\n",
    "texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_board_aug = nac.KeyboardAug(aug_char_max=2, aug_word_max=2)\n",
    "key_board_texts = key_board_aug.augment(texts)\n",
    "key_board_texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonym_aug = naw.SynonymAug(aug_max=2)\n",
    "synonym_texts = synonym_aug.augment(texts)\n",
    "synonym_texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load contextual words\n",
    "contextual_words_aug = naw.ContextualWordEmbsAug(model_path='distilbert-base-uncased', aug_max=4, device='cuda')\n",
    "contextual_words_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextual_words = []\n",
    "\n",
    "for i in range(0, len(texts), 64):\n",
    "    if i%1024==0:\n",
    "        print(f\"{i}/{len(texts)}\")\n",
    "    contextual_words += contextual_words_aug.augment(texts[i: i + 64])\n",
    "\n",
    "contextual_words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_translation_aug = nac.BackTranslationAug(aug_char_max=2)\n",
    "back_translation_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_translation_texts = []\n",
    "\n",
    "for i in range(0, len(texts), 64):\n",
    "    if i%1024==0:\n",
    "        print(f\"{i}/{len(texts)}\")\n",
    "    contextual_words += contextual_words_aug.augment(texts[i: i + 64])\n",
    "\n",
    "back_translation_texts = back_translation_aug.augment(texts)\n",
    "back_translation_texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_texts = key_board_texts + synonym_texts + contextual_words  + back_translation_texts\n",
    "new_texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nlpaug = pd.DataFrame({'question_text': new_texts, 'target': np.ones(len(new_texts))})\n",
    "df_nlpaug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nlpaug = pd.concat([train_df, df_nlpaug])\n",
    "train_nlpaug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nlpaug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nlpaug.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train datasets\n",
    "resampled_df.to_csv(\"../data/ros/train.csv\")\n",
    "train_nlpaug.to_csv(\"../data/nlpaug/train.csv\")\n",
    "\n",
    "# nlpaug\n",
    "test_df.to_csv(\"../data/processed/test.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9e9582e8547f3228029591ab69722d0e7c67d7caf2f49c6003d3efa221005ccd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
